{
  
    
        "post0": {
            "title": "NCAA Embeddings",
            "content": "Intro . One of my big projects this past year was preparing to my first Kaggle competition - both the NCAA Men&#39;s and Women&#39;s basketball tournaments! Unfortunately, the NCAA tournament was cancelled due to the Covid-19 pandemic. Regardless, working through my different ideas was a great way to learn some of the basics and nuances of training an ML model effectively. . I tried a few different types of models including a simple 2 layer neural net using FastAI and an ensemble model (XGBoost). These were relatively comprable and both required a similar level of feature engineering to get a good result (I think due to the limited data set - ~64 games per year since 2003 with the detailed game data). The results were fine, but I was wondering if there was a solution that could allow for less feature engineering and still give a reasonable result. . Enter embeddings... in this notebook I&#39;m going to explore a simple Keras implementation of embeddings to represent each NCAA team (e.g. Duke 2019 $ neq$ Duke 2020). For now, I will use those embeddings to perform some exploratory analysis to verify that they have learned useful features and in a following notebook I will use these embeddings as input features to an NCAA tournament model. This work was inspired by this Kaggle notebook. Though the predictions aren&#39;t spectacular, I think the exploratory analysis shows that embeddings could be a useful feature if paired with more detailed data and a model refined to predict NCAA tournament games as opposed to regular season games. . What you will see in this notebook at a high level: . Brief data prep - we are only using wins/losses, points, home/away, and team IDs as inputs to the model. *This work will later be expanded to incorporate more advanced statistics. | Model build - This model is being built with the sole purpose of generating useful embeddings. To achieve that we are training the model to be predictive of features that we would ordinarily use as feature inputs to a real tournament model (in this case, regular season wins and losses). | Training and validation - the model is trained using only regular season data from all years and is validated on a secondary set of tournament data (NIT). This is difficult because we have a slight mismatch between our training and validation data. The validation data is generally similar and likely more representative of the real NCAA tournament. | Sense check and exploratory analysis - First thing is to check that predictions from the model are sensisble, but what we really care about is the embeddings. Do they carry more useful information than simple aggregations of the data they represent? In short, Yes! | . Packages and Data . I&#39;ll be implementing this in Keras. My previous attempt using FastAI was quick and easy. Using embeddings for categorical data made the FastAI model a bit more elegant than XGBoost. However, we need two input variables (team 1 and team 2) to call the same embeddings matrix in this solution. FastAI can&#39;t do that out of the box and so I get to venture into the world of building my own in Keras. I plan on going one step deeper and building my final tournament model with TensorFlow. . #collapse_hide from pathlib import Path import numpy as np import pandas as pd np.random.seed(13) import tensorflow as tf import keras as k from keras.models import Model from keras.layers import Dense, Input, Dropout, Activation, Multiply, Lambda, Concatenate, Subtract, Flatten from keras.layers.embeddings import Embedding from keras.initializers import glorot_uniform, glorot_normal from keras.optimizers import Adam import matplotlib.pyplot as plt from scipy import stats from sklearn.manifold.t_sne import TSNE import altair as alt np.random.seed(13) . . Using TensorFlow backend. . I will be training the embeddings using total point and point differential from each game. Because the training doesn&#39;t require the more detailed NCAA data set, we can train using NCAA data all the way back to 1985. Hopfully this will make the weights of the other layers more robust. Depending on the embedding results, the final tournament model could also be trained back to 1985. Let&#39;s preview the first few rows of that regular season data here: . #collapse_hide dataLoc=Path(&#39;./data/2020-05-04-NCAA-Embeddings/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament/MDataFiles_Stage2/&#39;) df_teams = pd.read_csv(dataLoc/&#39;MTeams.csv&#39;) teams_dict = df_teams[[&#39;TeamID&#39;,&#39;TeamName&#39;]].set_index(&#39;TeamID&#39;).to_dict()[&#39;TeamName&#39;] df_regSeason_data = pd.read_csv(dataLoc/&#39;MRegularSeasonCompactResults.csv&#39;) df_regSeason_data.head() # cols = Season,DayNum,WTeamID,WScore,LTeamID,LScore,WLoc,NumOT . . Season DayNum WTeamID WScore LTeamID LScore WLoc NumOT . 0 1985 | 20 | 1228 | 81 | 1328 | 64 | N | 0 | . 1 1985 | 25 | 1106 | 77 | 1354 | 70 | H | 0 | . 2 1985 | 25 | 1112 | 63 | 1223 | 56 | H | 0 | . 3 1985 | 25 | 1165 | 70 | 1432 | 54 | H | 0 | . 4 1985 | 25 | 1192 | 86 | 1447 | 74 | H | 0 | . I want to be able to validate that the embedding training is going in the right direction. For the embedding training I will use the secondary tournament data. This allows us to avoid using the NCAA tournament data that we need for training/testing later, but still get a sense that the embeddings are useful. Here is a preview of that data: . #collapse_hide df_otherTourney_data = pd.read_csv(dataLoc/&#39;MSecondaryTourneyCompactResults.csv&#39;).drop(columns=&#39;SecondaryTourney&#39;) df_otherTourney_data.head() # cols = Season,DayNum,WTeamID,WScore,LTeamID,LScore,WLoc,NumOT . . Season DayNum WTeamID WScore LTeamID LScore WLoc NumOT . 0 1985 | 136 | 1151 | 67 | 1155 | 65 | H | 0 | . 1 1985 | 136 | 1153 | 77 | 1245 | 61 | H | 0 | . 2 1985 | 136 | 1201 | 79 | 1365 | 76 | H | 0 | . 3 1985 | 136 | 1231 | 79 | 1139 | 57 | H | 0 | . 4 1985 | 136 | 1249 | 78 | 1222 | 71 | H | 0 | . Embeddings will be defined by the columns &#39;Season&#39;, &#39;WTeamID&#39;, and &#39;LTeamID&#39;. &#39;WScore&#39; and &#39;LScore&#39; will be augmented slightly to be the predicted values and the game location will also be included as an embedding. . #collapse_hide # Create team encoding that differentiates teams by year and school def newTeamID(df): # df = df.sample(frac=1).reset_index(drop=True) df[&#39;Wnewid&#39;] = df[&#39;Season&#39;].astype(str) + df[&#39;WTeamID&#39;].astype(str) df[&#39;Lnewid&#39;] = df[&#39;Season&#39;].astype(str) + df[&#39;LTeamID&#39;].astype(str) return df df_regSeason_data = newTeamID(df_regSeason_data) df_otherTourney_data = newTeamID(df_otherTourney_data) def idDicts(df): newid_W = list(df[&#39;Wnewid&#39;].unique()) newid_L = list(df[&#39;Lnewid&#39;].unique()) ids = list(set().union(newid_W,newid_L)) ids.sort() oh_to_id = {} id_to_oh = {} for i in range(len(ids)): id_to_oh[ids[i]] = i oh_to_id[i] = ids[i] return oh_to_id, id_to_oh oh_to_id, id_to_oh = idDicts(df_regSeason_data) # add training data in swapped format so network sees both wins and losses def swapConcat_data(df): df[&#39;Wnewid&#39;] = df[&#39;Wnewid&#39;].apply(lambda x: id_to_oh[x]) df[&#39;Lnewid&#39;] = df[&#39;Lnewid&#39;].apply(lambda x: id_to_oh[x]) loc_dict = {&#39;A&#39;:-1,&#39;N&#39;:0,&#39;H&#39;:1} df[&#39;WLoc&#39;] = df[&#39;WLoc&#39;].apply(lambda x: loc_dict[x]) swap_cols = [&#39;Season&#39;, &#39;DayNum&#39;, &#39;LTeamID&#39;, &#39;LScore&#39;, &#39;WTeamID&#39;, &#39;WScore&#39;, &#39;WLoc&#39;, &#39;NumOT&#39;, &#39;Lnewid&#39;, &#39;Wnewid&#39;] df_swap = df[swap_cols].copy() df_swap[&#39;WLoc&#39;] = df_swap[&#39;WLoc&#39;]*-1 df.columns = [x.replace(&#39;WLoc&#39;,&#39;T1_Court&#39;) .replace(&#39;W&#39;,&#39;T1_&#39;) .replace(&#39;L&#39;,&#39;T2_&#39;) for x in list(df.columns)] df_swap.columns = df.columns df = pd.concat([df,df_swap]) df[&#39;Win&#39;] = (df[&#39;T1_Score&#39;]&gt;df[&#39;T2_Score&#39;]).astype(int) df[&#39;Close_Game&#39;]= abs(df[&#39;T1_Score&#39;]-df[&#39;T2_Score&#39;]) &lt;3 df[&#39;Score_diff&#39;] = df[&#39;T1_Score&#39;] - df[&#39;T2_Score&#39;] df[&#39;T2_Court&#39;] = df[&#39;T1_Court&#39;]*-1 df[[&#39;T1_Court&#39;,&#39;T2_Court&#39;]] = df[[&#39;T1_Court&#39;,&#39;T2_Court&#39;]] + 1 cols = df.columns.to_list() df = df[cols].sort_index() df.reset_index(drop=True,inplace=True) return df df_regSeason_full = swapConcat_data(df_regSeason_data.copy().sort_values(by=&#39;DayNum&#39;)) df_otherTourney_full = swapConcat_data(df_otherTourney_data.copy()) # Convert to numpy arrays in correct format def prep_inputs(df,id_to_oh, col_outputs): Xteams = np.stack([df[&#39;T1_newid&#39;].values,df[&#39;T2_newid&#39;].values]).T Xloc = np.stack([df[&#39;T1_Court&#39;].values,df[&#39;T2_Court&#39;].values]).T if len(col_outputs) &lt;2: Y_outputs = df[col_outputs].values Y_outputs = Y_outputs.reshape(len(Y_outputs),1) else: Y_outputs = np.stack([df[x].values for x in col_outputs]) return [Xteams, Xloc], Y_outputs X_train, Y_train = prep_inputs(df_regSeason_full, id_to_oh, [&#39;Win&#39;,&#39;Score_diff&#39;]) X_test, Y_test = prep_inputs(df_otherTourney_full, id_to_oh, [&#39;Win&#39;,&#39;Score_diff&#39;]) # Normalize point outputs - Win/loss unchanged def normalize_outputs(Y_outputs, stats_cache=None): if stats_cache == None: stats_cache = {} stats_cache[&#39;mean&#39;] = np.mean(Y_outputs,axis=1) stats_cache[&#39;var&#39;] = np.var(Y_outputs,axis=1) else: pass numOut = Y_outputs.shape[0] Y_normout = (Y_outputs-stats_cache[&#39;mean&#39;].reshape((numOut,1)))/stats_cache[&#39;var&#39;].reshape((numOut,1)) return Y_normout, stats_cache Y_norm_train, stats_cache_train = normalize_outputs(Y_train,None) Y_norm_test, _ = normalize_outputs(Y_test,stats_cache_train) Y_norm_train[0,:] = Y_train[0,:] Y_norm_test[0,:] = Y_test[0,:] . . Building the model . This model is built with two input types - home/away flags and team IDs. Each input is repeated for each team and is fed through a location embedding layer and a team embedding layer. A school&#39;s embeddings are separate season to season. It would nice to be able to cary some dependency from year to year, but that is completely disregarded here for simplicity. The location embedding is 1-dimensional and multiplied by each team&#39;s embedding vector element by element. The team embeddings are separately fed through the same two-layers before being subtracted. This subtracted layerinally connect to two output layers - one &#39;softmax&#39; for win/loss prediction and one dense layer with no activation for point prediction. . #collapse_show # build model tf.keras.backend.clear_session() def NCAA_Embeddings_Joint(nteams,teamEmb_size): team_input = Input(shape=[2,],dtype=&#39;int32&#39;, name=&#39;team_input&#39;) X_team = Embedding(input_dim=nteams, output_dim=teamEmb_size, input_length=2, embeddings_initializer=glorot_uniform(), name=&#39;team_encoding&#39;)(team_input) loc_input = Input(shape=[2,],dtype=&#39;int32&#39;, name=&#39;loc_input&#39;) X_loc = Embedding(input_dim=3, output_dim=1, input_length=2, embeddings_initializer=glorot_uniform(), name=&#39;loc_encoding&#39;)(loc_input) X_loc = Lambda(lambda z: k.backend.repeat_elements(z, rep=teamEmb_size, axis=-1))(X_loc) X = Multiply()([X_team,X_loc]) X = Dropout(rate=.5)(X) T1 = Lambda(lambda z: z[:,0,:])(X) T2 = Lambda(lambda z: z[:,1,:])(X) D1 = Dense(units = 20, use_bias=True, activation=&#39;tanh&#39;) DO1 = Dropout(rate=.5) D2 = Dense(units = 10, use_bias=True, activation=&#39;tanh&#39;) DO2 = Dropout(rate=.5) X1 = D1(T1) X1 = DO1(X1) X1 = D2(X1) X1 = DO2(X1) X2 = D1(T2) X2 = DO1(X2) X2 = D2(X2) X2 = DO2(X2) X_sub = Subtract()([X1,X2]) output_w= Dense(units = 1, use_bias=False, activation=&#39;sigmoid&#39;, name=&#39;win_output&#39;)(X_sub) output_p= Dense(units = 1, use_bias=False, activation=None, name=&#39;point_output&#39;)(X_sub) model = Model(inputs=[team_input, loc_input],outputs=[output_w,output_p],name=&#39;ncaa_embeddings_joint&#39;) return model mymodel = NCAA_Embeddings_Joint(len(id_to_oh),8) mymodel.summary() . . WARNING:tensorflow:From /Users/ryanarmstrong/opt/miniconda3/envs/ds37/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating: Colocations handled automatically by placer. Model: &#34;ncaa_embeddings_joint&#34; __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== loc_input (InputLayer) (None, 2) 0 __________________________________________________________________________________________________ team_input (InputLayer) (None, 2) 0 __________________________________________________________________________________________________ loc_encoding (Embedding) (None, 2, 1) 3 loc_input[0][0] __________________________________________________________________________________________________ team_encoding (Embedding) (None, 2, 8) 92752 team_input[0][0] __________________________________________________________________________________________________ lambda_1 (Lambda) (None, 2, 8) 0 loc_encoding[0][0] __________________________________________________________________________________________________ multiply_1 (Multiply) (None, 2, 8) 0 team_encoding[0][0] lambda_1[0][0] __________________________________________________________________________________________________ dropout_1 (Dropout) (None, 2, 8) 0 multiply_1[0][0] __________________________________________________________________________________________________ lambda_2 (Lambda) (None, 8) 0 dropout_1[0][0] __________________________________________________________________________________________________ lambda_3 (Lambda) (None, 8) 0 dropout_1[0][0] __________________________________________________________________________________________________ dense_1 (Dense) (None, 20) 180 lambda_2[0][0] lambda_3[0][0] __________________________________________________________________________________________________ dropout_2 (Dropout) (None, 20) 0 dense_1[0][0] dense_1[1][0] __________________________________________________________________________________________________ dense_2 (Dense) (None, 10) 210 dropout_2[0][0] dropout_2[1][0] __________________________________________________________________________________________________ dropout_3 (Dropout) (None, 10) 0 dense_2[0][0] dense_2[1][0] __________________________________________________________________________________________________ subtract_1 (Subtract) (None, 10) 0 dropout_3[0][0] dropout_3[1][0] __________________________________________________________________________________________________ win_output (Dense) (None, 1) 10 subtract_1[0][0] __________________________________________________________________________________________________ point_output (Dense) (None, 1) 10 subtract_1[0][0] ================================================================================================== Total params: 93,165 Trainable params: 93,165 Non-trainable params: 0 __________________________________________________________________________________________________ . Training the model . The model is trained using regular season data and validated using secondary tournament data (not the &#39;Big Dance&#39;). The weights of the two losses are adjusted so that they propogate a similar amount of error backward. Because the point differential data has been normalized, the losses are multiple orders of magnitude less than the log loss metric for wins/losses. . #collapse_show # Joint model optimizer = Adam(learning_rate=.01, beta_1=0.9, beta_2=0.999, amsgrad=False) mymodel.compile(loss=[&#39;binary_crossentropy&#39;,&#39;logcosh&#39;], loss_weights=[.5,400], optimizer=optimizer, metrics = [&#39;accuracy&#39;]) numBatch = round(X_train[0].shape[0]/50) results = mymodel.fit(X_train, [*Y_norm_train], validation_data=(X_test, [*Y_norm_test]), epochs = 35, batch_size = numBatch,shuffle=True, verbose=False) . . WARNING:tensorflow:From /Users/ryanarmstrong/opt/miniconda3/envs/ds37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating: Use tf.cast instead. . #collapse_hide accuracy = results.history[&#39;win_output_accuracy&#39;] val_accuracy = results.history[&#39;val_win_output_accuracy&#39;] loss = results.history[&#39;win_output_loss&#39;] val_loss = results.history[&#39;val_win_output_loss&#39;] # summarize history for accuracy plt.plot(accuracy) plt.plot(val_accuracy) plt.title(&#39;model accuracy&#39;) plt.ylabel(&#39;accuracy&#39;) plt.xlabel(&#39;epoch&#39;) plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;) plt.show() # summarize history for loss plt.plot(loss) plt.plot(val_loss) plt.title(&#39;model loss&#39;) plt.ylabel(&#39;loss&#39;) plt.xlabel(&#39;epoch&#39;) plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;) plt.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Results . The crossplots for point differential and win/loss are generally well behaved. The loss and accuracy of the model are not great in comparison to results from the Kaggle competition. For reference, anything below a loss of 0.5 would be considered fantastic and flipping a coin would give you a loss of about 0.69. We see a similar effect in the point spread prediction with a rather loose correlation of 0.46. . If the goal of this project was to have the best model for predicting the winner of an NCAA tournament game we would be failing (especially considering only the best play in the tournament - making predictions even harder). However, the goal here was to train embeddings not to get accurate predictions. Instead, we are using regular season data to train an embedding set that is representative of each team. We have only trained on wins/losses and points in this case, which might limit the utility of the features. Converserly, we will see in the next section that we have achieved a richer representation of the raw win/loss data than simply aggregating by teams. . #collapse_hide def transform_y(preds,stats_cache): preds = stats_cache[&#39;var&#39;][1] * preds + stats_cache[&#39;mean&#39;][1] return preds preds = mymodel.predict(X_test) tmp=0 x = transform_y(preds[1],stats_cache_train).reshape(-1) y = transform_y(Y_norm_test[1],stats_cache_train).reshape(-1) print(&#39;Pearson coefficient: &#39;, round(stats.pearsonr(x, y)[0]*100)/100) plt.scatter(x, y, alpha=0.08) # plt.title(&#39;Scatter plot pythonspot.com&#39;) plt.xlabel(&#39;Predicted point difference&#39;) plt.ylabel(&#39;Actual point difference&#39;) plt.show() . . Pearson coefficient: 0.47 . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; #collapse_hide x = preds[0].reshape(-1) plt.hist(x,bins=100) # plt.title(&#39;Scatter plot pythonspot.com&#39;) plt.xlabel(&#39;Predicted Win Probability&#39;) plt.ylabel(&#39;Count&#39;) plt.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; One notable aspect of the point prediction result is that the predictions are perfectly symmetrical. The network is able to give consistent predictions for &quot;Team A vs. Team B&quot; and &quot;Team B vs. Team A&quot; because the neural network is set up to treat the input features consistently for each team. Other ML models, such as XGBoost, treat the feature inputs of Team 1 and Team 2 differently, which can result in varying predictions when the teams are swapped. This can be an issue even when training sets contain matchups and swapped matchups as documented in this discussion. . Exploratory Analysis . Let&#39;s take a look at some comparisons between our embeddings (mapped non-linearly into 2D space by T-SNE) vs. the aggregated point differential and win percentage of each team. All of these plots (excluding the final plot for 2020) will only include teams that were included in the NCAA tournament that year. . We&#39;ll color the scatter plots by a few different factors: . Highlighting tournament winners | Tournament seed number | Number of tournament games won | Biggest opening weekend upsets according to this article | . Here is a preview of the data that will be fed into the visualizations: . #collapse_hide embeddings = mymodel.layers[3].get_weights()[0] t = TSNE(n_components=2) embed_tsne = t.fit_transform(embeddings) df_regSeason_full[&#39;T1_TeamName&#39;] = df_regSeason_full[&#39;T1_TeamID&#39;].apply(lambda x: teams_dict[x]) + &#39;-&#39; + df_regSeason_full[&#39;Season&#39;].astype(str) df_agg=df_regSeason_full.groupby(&#39;T1_TeamName&#39;).mean() df_agg.reset_index(inplace=True,drop=False) df_agg[[&#39;T1_TeamName&#39;,&#39;Win&#39;,&#39;Score_diff&#39;]] df_agg.drop(columns=&#39;Season&#39;,inplace=True) df_tourney_data = pd.read_csv(dataLoc/&#39;MNCAATourneyCompactResults.csv&#39;) df_tourney_data[&#39;WTeamName&#39;] = df_tourney_data[&#39;WTeamID&#39;].apply(lambda x: teams_dict[x]) + &#39;-&#39; + df_tourney_data[&#39;Season&#39;].astype(str) df_tourney_data[&#39;Wins&#39;] = 0 df_wins = df_tourney_data[[&#39;WTeamName&#39;,&#39;Wins&#39;]].groupby(&#39;WTeamName&#39;).count() tourneyWinners = [df_tourney_data.loc[df_tourney_data[&#39;Season&#39;]==s,&#39;WTeamName&#39;].values[-1] for s in df_tourney_data[&#39;Season&#39;].unique()] df_seeds = pd.read_csv(dataLoc/&#39;MNCAATourneySeeds.csv&#39;) df_seeds[&#39;TeamName&#39;] = df_seeds[&#39;TeamID&#39;].apply(lambda x: teams_dict[x]) + &#39;-&#39; + df_seeds[&#39;Season&#39;].astype(str) df_seeds[&#39;Seed&#39;] = df_seeds[&#39;Seed&#39;].str.extract(r&#39;( d+)&#39;) df_seeds[&#39;WonTourney&#39;] = df_seeds[&#39;TeamName&#39;].apply(lambda x: True if x in tourneyWinners else False) df_seeds = df_seeds[[&#39;TeamName&#39;,&#39;Seed&#39;,&#39;WonTourney&#39;]] df_upsets = pd.read_csv(&#39;./data/2020-05-04-NCAA-Embeddings/Upsets.csv&#39;) df_upsets[&#39;David&#39;]=df_upsets[&#39;David&#39;]+&#39;-&#39;+df_upsets[&#39;Season&#39;].astype(str) df_upsets[&#39;Goliath&#39;]=df_upsets[&#39;Goliath&#39;]+&#39;-&#39;+df_upsets[&#39;Season&#39;].astype(str) upsets = {} for ii in df_upsets[&#39;David&#39;].unique(): upsets[ii] = &#39;Surprise&#39; for ii in df_upsets[&#39;Goliath&#39;].unique(): upsets[ii] = &#39;Bust&#39; df_seeds = pd.merge(left=df_seeds, right=df_wins, how=&#39;left&#39;, left_on=&#39;TeamName&#39;,right_index=True) df_seeds[&#39;Wins&#39;].fillna(0,inplace=True) def upset(x): try: y = upsets[x] except: y = None return y df_seeds[&#39;Upset&#39;] = df_seeds[&#39;TeamName&#39;].apply(lambda x: upset(x)) df = pd.DataFrame(embed_tsne,columns=[&#39;factor1&#39;,&#39;factor2&#39;]) df[&#39;TeamName&#39;] = [str(teams_dict[int(oh_to_id[x][-4:])]) + &#39;-&#39; + oh_to_id[x][:4] for x in df.index] df[&#39;Season&#39;] = [int(oh_to_id[x][:4])for x in df.index] df = pd.merge(left=df, right=df_seeds, how=&#39;left&#39;, on=&#39;TeamName&#39;) df = pd.merge(left=df, right=df_agg, how=&#39;left&#39;, left_on=&#39;TeamName&#39;,right_on=&#39;T1_TeamName&#39;) df = df[[&#39;TeamName&#39;,&#39;Season&#39;,&#39;factor1&#39;,&#39;factor2&#39;,&#39;Win&#39;,&#39;Score_diff&#39;,&#39;Seed&#39;,&#39;Wins&#39;,&#39;Upset&#39;,&#39;WonTourney&#39;]] df.columns = [&#39;TeamName&#39;,&#39;Season&#39;,&#39;factor1&#39;,&#39;factor2&#39;,&#39;RegWins&#39;,&#39;RegPoint_diff&#39;,&#39;Seed&#39;,&#39;TourneyWins&#39;,&#39;Upset&#39;,&#39;WonTourney&#39;] df2020 = df[df[&#39;Season&#39;]==2020].copy() df.dropna(inplace=True,subset=[&#39;Seed&#39;]) df[&#39;TourneyWinsScaled&#39;] = df[&#39;TourneyWins&#39;]/df[&#39;TourneyWins&#39;].max() df[&#39;SeedScaled&#39;] = df[&#39;Seed&#39;].astype(int)/df[&#39;Seed&#39;].astype(int).max() df.head() . . TeamName Season factor1 factor2 RegWins RegPoint_diff Seed TourneyWins Upset WonTourney TourneyWinsScaled SeedScaled . 2 Alabama-1985 | 1985 | 25.801876 | 32.783264 | 0.700000 | 7.800000 | 07 | 2.0 | None | False | 0.333333 | 0.4375 | . 8 Arizona-1985 | 1985 | -4.960138 | 60.523514 | 0.666667 | 7.185185 | 10 | 0.0 | None | False | 0.000000 | 0.6250 | . 11 Arkansas-1985 | 1985 | 15.780385 | 58.555176 | 0.636364 | 3.636364 | 09 | 1.0 | None | False | 0.166667 | 0.5625 | . 14 Auburn-1985 | 1985 | 2.921161 | 67.866516 | 0.620690 | 3.689655 | 11 | 2.0 | None | False | 0.333333 | 0.6875 | . 21 Boston College-1985 | 1985 | 32.161552 | 57.934296 | 0.615385 | 5.269231 | 11 | 2.0 | None | False | 0.333333 | 0.6875 | . . Important: For the following plots T-SNE representations of trained embeddings will be on the left and mean regular season statistics will be on the right. . #collapse_hide xrange_tsne = [-80,100] yrange_tsne = [-80,100] xrange_raw = [-20,40] trange_raw = [.2,1.2] selector = alt.selection_single(empty=&#39;all&#39;, fields=[&#39;TeamName&#39;]) base = alt.Chart(df).mark_point(filled=True,size=50).encode( color=alt.condition(selector, alt.Color(&#39;WonTourney:N&#39;, scale=alt.Scale(scheme=&#39;tableau10&#39;)), alt.value(&#39;lightgray&#39;) ), order=alt.Order(&#39;WonTourney:N&#39;, sort=&#39;ascending&#39;), tooltip=[&#39;TeamName&#39;,&#39;Seed&#39;] ).properties( width=250, height=250 ).add_selection(selector).interactive() chart1 = [alt.X(&#39;factor1:Q&#39;, scale=alt.Scale(domain=xrange_tsne), axis=alt.Axis(title=&#39;T-SNE factor 1&#39;)), alt.Y(&#39;factor2:Q&#39;, scale=alt.Scale(domain=yrange_tsne), axis=alt.Axis(title=&#39;T-SNE factor 2&#39;)) ] chart2 = [alt.X(&#39;RegPoint_diff:Q&#39;, scale=alt.Scale(domain=xrange_raw), axis=alt.Axis(title=&#39;Average Regular Season Point Difference&#39;)), alt.Y(&#39;RegWins:Q&#39;, scale=alt.Scale(domain=yrange_raw), axis=alt.Axis(format=&#39;%&#39;, title=&#39;Regular Season Win Percentage&#39;)) ] base.encode(*chart1) | base.encode(*chart2) . . Tournament winners compared to the field (above): One interesting insight below is how significantly different the 1985 Villanova team is from the other tournament winners. Multiple websites (like this one) list the 1985 Villanova team winning the championship as one of the greatest underdog stories ever. This is far more evident in the T-SNE representation of the embeddings than the plots of win percentage vs. points. . #collapse_hide xrange_tsne=[-80,100] yrange_tsne=[-80,100] xrange_raw=[-20,40] yrange_raw=[.2,1.2] selector = alt.selection_single(empty=&#39;all&#39;, fields=[&#39;TeamName&#39;]) base = alt.Chart(df).mark_point(filled=True,size=35).encode( color=alt.condition(selector, alt.Color(&#39;Seed:Q&#39;, scale=alt.Scale(scheme=&#39;viridis&#39;,reverse=True)), alt.value(&#39;lightgray&#39;) ), order=alt.Order(&#39;Seed:Q&#39;, sort=&#39;descending&#39;), tooltip=[&#39;TeamName&#39;,&#39;Seed&#39;] ).properties( width=250, height=250 ).add_selection(selector).interactive() chart1 = [alt.X(&#39;factor1:Q&#39;, scale=alt.Scale(domain=xrange_tsne), axis=alt.Axis(title=&#39;T-SNE factor 1&#39;)), alt.Y(&#39;factor2:Q&#39;, scale=alt.Scale(domain=yrange_tsne), axis=alt.Axis(title=&#39;T-SNE factor 2&#39;)) ] chart2 = [alt.X(&#39;RegPoint_diff:Q&#39;, scale=alt.Scale(domain=xrange_raw), axis=alt.Axis(title=&#39;Average Regular Season Point Difference&#39;)), alt.Y(&#39;RegWins:Q&#39;, scale=alt.Scale(domain=yrange_raw), axis=alt.Axis(format=&#39;%&#39;, title=&#39;Regular Season Win Percentage&#39;)) ] base.encode(*chart1) | base.encode(*chart2) . . Colored by seed: We see a high correlation between the assigned seed and our embeddings. Our embeddings appear to be a better representation of the seeding than the aggregated statistics, which makes sense since our method uses pair-wise comparisons and effectively accounts for team strength while aggregated statistics do not. . #collapse_hide selector = alt.selection_single(empty=&#39;all&#39;, fields=[&#39;TeamName&#39;]) base = alt.Chart(df).mark_point(filled=True,size=35).encode( color=alt.condition(selector, alt.Color(&#39;TourneyWins:Q&#39;, scale=alt.Scale(scheme=&#39;viridis&#39;,reverse=False)), alt.value(&#39;lightgray&#39;) ), order=alt.Order(&#39;TourneyWins:Q&#39;, sort=&#39;ascending&#39;), tooltip=[&#39;TeamName&#39;,&#39;Seed&#39;] ).properties( width=250, height=250 ).add_selection(selector).interactive() chart1 = [alt.X(&#39;factor1:Q&#39;, scale=alt.Scale(domain=xrange_tsne), axis=alt.Axis(title=&#39;T-SNE factor 1&#39;)), alt.Y(&#39;factor2:Q&#39;, scale=alt.Scale(domain=yrange_tsne), axis=alt.Axis(title=&#39;T-SNE factor 2&#39;)) ] chart2 = [alt.X(&#39;RegPoint_diff:Q&#39;, scale=alt.Scale(domain=xrange_raw), axis=alt.Axis(title=&#39;Average Regular Season Point Difference&#39;)), alt.Y(&#39;RegWins:Q&#39;, scale=alt.Scale(domain=yrange_raw), axis=alt.Axis(format=&#39;%&#39;, title=&#39;Regular Season Win Percentage&#39;)) ] base.encode(*chart1) | base.encode(*chart2) . . Colored by number of NCAA tournament games won that year: The embeddings appear to be far less correlated to the number of games won by tournament. This is logical since, unlike the seeds, this statistic is not at all represented in the training set. . #collapse_hide selector = alt.selection_single(empty=&#39;all&#39;, fields=[&#39;TeamName&#39;]) base = alt.Chart(df).mark_point(filled=True,size=50).encode( color=alt.condition(selector, alt.Color(&#39;Upset:N&#39;, scale=alt.Scale(scheme=&#39;tableau10&#39;)), alt.value(&#39;lightgray&#39;) ), order=alt.Order(&#39;Upset:N&#39;, sort=&#39;ascending&#39;), tooltip=[&#39;TeamName&#39;,&#39;Seed&#39;] ).properties( width=250, height=250 ).add_selection(selector).interactive() chart1 = [alt.X(&#39;factor1:Q&#39;, scale=alt.Scale(domain=xrange_tsne), axis=alt.Axis(title=&#39;T-SNE factor 1&#39;)), alt.Y(&#39;factor2:Q&#39;, scale=alt.Scale(domain=yrange_tsne), axis=alt.Axis(title=&#39;T-SNE factor 2&#39;)) ] chart2 = [alt.X(&#39;RegPoint_diff:Q&#39;, scale=alt.Scale(domain=xrange_raw), axis=alt.Axis(title=&#39;Average Regular Season Point Difference&#39;)), alt.Y(&#39;RegWins:Q&#39;, scale=alt.Scale(domain=yrange_raw), axis=alt.Axis(format=&#39;%&#39;, title=&#39;Regular Season Win Percentage&#39;)) ] base.encode(*chart1) | base.encode(*chart2) . . Biggest upsets - underdogs in red: Generally, the model agrees with the experts. These were upsets and wouldn&#39;t have been predicted by this method. If anything this method would likely have predicted no upset with even greater conviction tahn a model trained on just aggregated points and wins. The only exception to this is the 1986 &quot;upset&quot; of Cleveland State over the Indiana Hoosiers. Both the embeddings model and the aggregated statistics indicate that Cleveland State may have been the better team. Perhaps it was an issue of name recognition that lead this to be called an upset? . #collapse_hide ## create slider and brush select_year = alt.selection_single( name=&#39;select&#39;, fields=[&#39;Season&#39;], init={&#39;Season&#39;: 1985}, bind=alt.binding_range(min=1985, max=2019, step=1)) selector = alt.selection_single(empty=&#39;all&#39;, fields=[&#39;TeamName&#39;]) ## create base for charts base = alt.Chart(df).mark_point(filled=True,size=50).encode( color=alt.condition(selector, alt.Color(&#39;TourneyWins:Q&#39;, scale=alt.Scale(scheme=&#39;viridis&#39;,reverse=False)), alt.value(&#39;lightgray&#39;) ), order=alt.Order(&#39;Seed:Q&#39;, sort=&#39;descending&#39;), tooltip=[&#39;TeamName&#39;,&#39;Seed&#39;] ).properties( width=250, height=250 ).add_selection(select_year).transform_filter(select_year).add_selection(selector).interactive() chart1 = [alt.X(&#39;factor1:Q&#39;, scale=alt.Scale(domain=xrange_tsne), axis=alt.Axis(title=&#39;T-SNE factor 1&#39;)), alt.Y(&#39;factor2:Q&#39;, scale=alt.Scale(domain=yrange_tsne), axis=alt.Axis(title=&#39;T-SNE factor 2&#39;)) ] chart2 = [alt.X(&#39;RegPoint_diff:Q&#39;, scale=alt.Scale(domain=xrange_raw), axis=alt.Axis(title=&#39;Average Regular Season Point Difference&#39;)), alt.Y(&#39;RegWins:Q&#39;, scale=alt.Scale(domain=yrange_raw), axis=alt.Axis(format=&#39;%&#39;, title=&#39;Regular Season Win Percentage&#39;)) ] base.encode(*chart1) | base.encode(*chart2) . . Number of games won split out by season - yellow dot is tournament winner: The spread of teams is quite variable year to year. Notably, the tournament that the 1985 Villanova team won as a heavy underdog has less spread in the competition than other years. . #collapse_hide ## 2020 plot selector = alt.selection_single(empty=&#39;all&#39;, fields=[&#39;TeamName&#39;]) base = alt.Chart(df2020).mark_point(filled=True,size=50).encode( color=alt.condition(selector, alt.Color(&#39;TeamName:N&#39;), alt.value(&#39;lightgray&#39;)), order=alt.Order(&#39;RegWins:Q&#39;, sort=&#39;ascending&#39;), tooltip=[&#39;TeamName&#39;] ).properties( width=250, height=250 ).add_selection(selector).interactive() chart1 = [alt.X(&#39;factor1:Q&#39;, scale=alt.Scale(domain=[-80,100]), axis=alt.Axis(title=&#39;T-SNE factor 1&#39;)), alt.Y(&#39;factor2:Q&#39;, scale=alt.Scale(domain=[-80,100]), axis=alt.Axis(title=&#39;T-SNE factor 2&#39;)) ] chart2 = [alt.X(&#39;RegPoint_diff:Q&#39;, scale=alt.Scale(domain=[-30,30]), axis=alt.Axis(title=&#39;Average Regular Season Point Difference&#39;)), alt.Y(&#39;RegWins:Q&#39;, scale=alt.Scale(domain=[0,1]), axis=alt.Axis(format=&#39;%&#39;, title=&#39;Regular Season Win Percentage&#39;)) ] base.encode(*chart1) | base.encode(*chart2) . . The 2020 field: Just for fun here is a taste of what we missed in 2020! . Conclusions . The embeddings apppear to have learned which teams are better and which are worse. It seems that they are a better representation of true team skill than simple aggregating the statistics used in model training (wins and point differentials). When the time comes to build a model for the 2021 March Madness Kaggle competition, I will likely return to embeddings as an advanced input feature for my final model, which will be trained on real tournament games! Then will be the time to experiment with training the team embeddings on advanced statistics included in the detailed Kaggle data set in place of or in addition to the target features used here. .",
            "url": "https://rysarmstr.github.io/Data-Bites-Blog/kaggle/2020/05/04/NCAA-Embeddings.html",
            "relUrl": "/kaggle/2020/05/04/NCAA-Embeddings.html",
            "date": " • May 4, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Getting Started",
            "content": "Intro . Hello, World! In my first real post I wanted to share some thoughts about resources for getting started in Python or data science. This has been nearly a 3 year process for me and could have been done much more effeciently - I&#39;ll point out a few of the ways I would do things differently if I were restarting today. Hopefully some of these tips can be helpful to others who are learning data science concepts at their own pace. I will try to keep this post updated with new resources as I find them. Keep in mind, as I&#39;m learning as we go so these comments will no doubt be incomplete. If you&#39;ve been through this process and have recommendations for things to improve or change please share them in the comments! . Python Install and Package Management . TL;DR: Read Ted Petrou&#39;s &quot;Anaconda is bloated.&quot; . First things first... 99% of what I write here will be about Python. As most beginners probably do, I started off by downloading Anaconda Navigator to keep things simple. The first mistake I made - against the advice of many experienced python users - was to not using python environments from the beginning. As I learned about package management and different versions of Python there were a few instances where I ended up with a messy environment and decided I wanted to restart. The simplest thing to me seemed to be (not in reality) a reinstall of Python. Long story short, I spent way more time fumbling my way through breaking and recreating my conda environments instead using that time to learn the actual packages. Eventually, I stumbled across Ted Petrou&#39;s &quot;Anaconda is bloated&quot;, which gives a fantastic overview of how to get a quick, effective data science set-up running in Python. Pairing this with a program like Visual Studio Code can get you up and running quickly with the ability to start over easily when/if the time comes. Next let&#39;s talk a bit about interfaces. . User Interface (IDE) Selection . TL;DR: If starting over today I would install Jupyter Notebooks, but use Visual Studio Code as my daily interface. VS Code is a great text editor, but also gives you the power of IPython Notebooks and the freedom to experiment with other innovative interfaces like Streamlit. . Of course, you can always write Python code in a simple text editor and run your scripts from terminal, but modern IDEs offer a lot of built in efficiencies. When I started down the path of learning Python, the idea of not having an official IDE, like MATLAB or RStudio, made me a little squeamish. I jumped straight into Jupyter Notebooks for the simplicity and was ecstatic when I learned about Jupyter Labs, which takes the interactivity of Jupyter Notebooks a step closer to the full IDE experience. The IPython Notebook, which is that basis for the Jupyter system is widely used across data science platforms like Kaggle and Coursera, which makes the transition from your machine to other platforms more seamless. The only thing I didn&#39;t like about the Jupyter environment was that I was locked into that interface. . What pushed me to try the oft-recommended VSCode was the introduction of a new interactive interface called Streamlit (more on Streamlit in a bit). In order to try Streamlit I needed a text editor that was separate from Jupyter Notebooks. What I found in VSCode was a text editor that runs IPython Notebooks, has a built in terminal for package/environment management (or git), and of course efficiently edits text files. I&#39;m still learning many of the creative editing shortcuts and I&#39;m sure I am not using the extensions to their full capability, but VS Code has become my primary workspace. . Lastly, I&#39;ll touch on Streamlit, a relatively new interface with a completely different take on interactive code. Streamlit runs the full code of your python script on every pass unlike IPython Notebooks which execute a single cell at a time. Streamlit allows compute-intensive functions to be cached so that they don&#39;t need to be re-run over and over. The shining feature that made me fall in love with Streamlit is its ability to add interactive features like buttons, sliders, dropdowns, or text input with a single line of code. These features make data exploration much faster in Streamlit and also provide a framework to build simple apps for people looking to deploy ML algorithms quickly. This video from the co-founder and CEO gives a great introduction to the interface. . Courses, Podcasts, and Other Resources . TL;DR: Sites like Kaggle that incentivize project building are a great place to start. Fill in knowledge gaps with resources like courses, but don&#39;t fall into the trap of doing courses endlessly with no applied experience. . I have spent the last 3 years or so learning python and then expanding into the world of machine learning and now deep learning. I can&#39;t say that it&#39;s been the most efficient process and I think an important take away is prioritizing efficiency when choosing your learning path. Not everyone has the same amount of time to dedicate. While a bootcamp might get you where you want to be in 6 months, it can be a large time (and monetary) commitment. Career Karma is an interesting place to start if you are interested in bootcamps but don&#39;t know where to start. For the rest of us, Dan Becker (creator of Kaggle Learn) explains in this episode of &quot;Chai Time Data Science&quot; that the first priority for anyone looking to move into a data science career should be building projects. Keeping that in mind, below you will find some of my favorite resources split out into those that are more conducive to building things quickly and others that are more helpful when you need to take a step back and just absorb some of the technical details. I&#39;ll leave it up to you to prioritize these in a way that works for you. . Quick hitters: . SoloLearn - Learn syntax for Python (don&#39;t spend too much time here!) | Agile Geoscience Kata (for the geologically-inclined) - These small coding challenges are a great way to learn some python basics, especially if you are a geoscientist who works with subsurface data. Likely not as useful for others. | Kaggle Learn - these courses have been specifically designed to get users into real use case examples of how machine learning is used to solve problems. The lessons are short, practical, and don&#39;t dwell on the details, but are enough to get you building. Coursera (see below) is a great alternative for more detailed learning. | FastAI - FastAI is organized in a similar way to Kaggle Learn. Jeremy Howard gets you training deep neural networks within the first video lecture and provides insights along the way. Again, Coursera is an alternative reference if you eventually want to learn to build your own networks from scratch. | TWIML Podcast - The TWIML AI podcast offers a large catalog of interviews with data scientists applying ML/DL. These may be difficult to follow along until you have a bit of experience, but the TWIML AI community also offers study groups and other resources that you may find useful. | Kaggle Competitions - As your skillset grows you can start applying what you are learning and discussing your results with the helpful community on Kaggle. My personal favorite is the yearly March Madness competition, which was unfortunately cancelled due to the Covid-19 pandemic. Will try again next year! | . More Detailed/Traditional Learning . Machine Learning Guide (Podcast) - Very high level overviews of data science and types of languages/algorithms. Similar content can be found on the web, but this may be a useful resource if you are a beginner looking for something to listen to on your commute or when you can&#39;t be on a computer. | Coursera - If you need more detail than Kaggle Learn the applied lessons, there is a lot of content on Coursera. A few examples of commonly recommended courses: Python for Everybody - The first few courses of this specialization will give you a crash course in python. It will provide more detail and active learning than something like SoloLearn, which is designed to be short and sweet. | Machine Learning great content as an introduction to the fundamentals of machine learning, but unfortunately taught in Octave or MATLAB. There is significant overlap between this course and the Deep Learning course below - you may actually try that first and see if you need to back track. | Deep Learning - This course will introduce fundamental concepts related to building and training deep neural networks. Expect more theory and free-form coding than the FastAI course. As you get into coding in TensorFlow, this intro to TensorFlow fundamentals is also very useful document. | . | . Hopefully, these resources can be of help or at least get you moving in the right direction as you start your personal data science journey! .",
            "url": "https://rysarmstr.github.io/Data-Bites-Blog/python/2020/04/26/Getting-Started.html",
            "relUrl": "/python/2020/04/26/Getting-Started.html",
            "date": " • Apr 26, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Introduction",
            "content": "Why the blog? . I&#39;ve spent my career studying geology and physics and have a passion for understanding the cause of natural phenomena. I have lots of experience looking at large data sets - seismic, gravity, magnetics, electromagnetics, and miscellaneous subsurface geologic data. Most of these projects have been done in MATLAB and ArcGIS. . More recently I&#39;ve started honing data science skills to bring my intuitions about data exploration and data analysis into the world of machine learning and replicable data science using python frameworks and git. Until now, I haven&#39;t had a clear project or structured place to put my mini-projects. Now, this blog can serve as that space! Whether it&#39;s simple visualizations with geologic data or building neural networks to predict March Madness brackets - I will aim to document it here! . Where in the world?! . I am currently a Gulf of Mexico exploration geophysicist for Hess Corporation in Houston, TX. I spend most of my time intepreting subsurface data and following seismic data reprocessing projects, but my past experiences have been much more varied. Below are a few of my past roles and projects: . Past Experiences at Hess Building workflows for cataloging well-based seismic amplitude analysis at a regional scale - Gulf of Mexico, USA | Stratigraphic mapping of regional shallow hazards - Tano Basin, Ghana | Data visualization using Spotfire for a geochemistry database | Basin Scale Play Evaluation for New Ventures - Atlantic Margins (Ireland, Brazil, Sierra Leone, South Africa, Mauritania, Senegal) | Prospect analysis and well planning - Offshore Newfoundland, CA | . | Reserseach Assistant - University of Wyoming Processing and interpretation of airborne electromagnetic survey - Snowy Range, WY | Geophysical data collection (Seismic refraction, ERT, GPR, Magnetics, NMR) - WY and CA | . | IRIS internship and eventual senior thesis on repeating earthquakes near Christchurch, New Zealand - Research at University of Wisconsin - Madison (thesis at Colorado College) | .",
            "url": "https://rysarmstr.github.io/Data-Bites-Blog/2020/04/25/Introduction.html",
            "relUrl": "/2020/04/25/Introduction.html",
            "date": " • Apr 25, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". I’m a geoscientist by background with a strong desire to uncover the “why” of challenging problems. I’ve spent my career studying geologic, geophysical, and environmental data, but spend much of my free time trolling through other publicly available data. . As I continue to learn more python and vizualization skills I will be sharing my learnings and insights here on this blog. Please visit this page or visit my LinkedIn for more details on my background in geoscience and physics. .",
          "url": "https://rysarmstr.github.io/Data-Bites-Blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://rysarmstr.github.io/Data-Bites-Blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}